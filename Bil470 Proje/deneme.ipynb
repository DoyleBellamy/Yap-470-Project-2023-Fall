{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from joblib import load\n",
    "import pickle\n",
    "from node2vec import Node2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from networkx.algorithms import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Big_Graphs():\n",
    "    num_nodes = 2000\n",
    "    BigList_2000 =[]\n",
    "    random_complete = nx.complete_graph(2000)\n",
    "    for i in range(2000):\n",
    "        for j in range(i + 1, 2000):\n",
    "            if random.random() < 0.5:\n",
    "                random_complete.remove_edge(i, j)\n",
    "    BigList_2000.append(random_complete)\n",
    "    #-------------------------------------------------\n",
    "    random_multigraph = nx.MultiGraph()\n",
    "    for i in range(num_nodes):\n",
    "        random_multigraph.add_node(i)\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            if random.random() < 0.5:\n",
    "                random_multigraph.add_edge(i, j)\n",
    "    BigList_2000.append(random_multigraph)\n",
    "    #-------------------------------------------------\n",
    "    pseudograph = nx.MultiGraph()\n",
    "    pseudograph.add_nodes_from(range(num_nodes))\n",
    "    for node in pseudograph.nodes():\n",
    "        pseudograph.add_edge(node, node)\n",
    "        random_nodes = random.sample(pseudograph.nodes(), k=3)\n",
    "        pseudograph.add_edges_from([(node, random_node) for random_node in random_nodes])\n",
    "    BigList_2000.append(pseudograph)\n",
    "    #-------------------------------------------------\n",
    "    planar_graph = nx.random_geometric_graph(num_nodes, radius=0.2)\n",
    "    while not nx.is_connected(planar_graph):\n",
    "        planar_graph = nx.random_geometric_graph(num_nodes, radius=0.2)\n",
    "    BigList_2000.append(planar_graph)\n",
    "    #-------------------------------------------------\n",
    "    def random_hamiltonian_graph(n):\n",
    "        graph = nx.random_regular_graph(2, n)\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                if random.random() < 0.5 and not graph.has_edge(i, j):\n",
    "                    graph.add_edge(i, j)\n",
    "        return graph\n",
    "    random_hamiltonian_graph = random_hamiltonian_graph(num_nodes)\n",
    "    BigList_2000.append(random_hamiltonian_graph)\n",
    "    return BigList_2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_main_graphs(num_nodes):\n",
    "    main_list =[]\n",
    "    random_regular_3 = nx.random_regular_graph(3, num_nodes)\n",
    "    random_regular_20 = nx.random_regular_graph(20, num_nodes)\n",
    "    main_list.append(random_regular_3)\n",
    "    main_list.append(random_regular_20)\n",
    "    #-------------------------------------------------\n",
    "    # Create a random connected graph by generating a random spanning tree\n",
    "    random_connected_tree = nx.random_tree(num_nodes)\n",
    "    # Add additional edges to maintain connectivity\n",
    "    while not nx.is_connected(random_connected_tree):\n",
    "        node1 = random.choice(list(random_connected_tree.nodes()))\n",
    "        node2 = random.choice(list(random_connected_tree.nodes()))\n",
    "        if node1 != node2 and not random_connected_tree.has_edge(node1, node2):\n",
    "            random_connected_tree.add_edge(node1, node2)\n",
    "    main_list.append(random_connected_tree)\n",
    "    #-------------------------------------------------\n",
    "    def generate_random_connected_cycle_graph(num_nodes):\n",
    "        if num_nodes < 3:\n",
    "            raise ValueError(\"Number of nodes must be at least 3 for a cycle.\")\n",
    "        cycle_graph = nx.cycle_graph(num_nodes)\n",
    "        # Connect the cycle to form a connected cycle graph\n",
    "        connected_cycle_graph = nx.connected_watts_strogatz_graph(num_nodes, 2, 0.1)\n",
    "        return connected_cycle_graph\n",
    "    random_cycle_graph = generate_random_connected_cycle_graph(num_nodes)\n",
    "    main_list.append(random_cycle_graph)\n",
    "    #-------------------------------------------------\n",
    "    def generate_random_connected_barabasi_albert_graph(num_nodes, m):\n",
    "        if num_nodes <= m:\n",
    "            raise ValueError(\"Number of nodes must be greater than m for a BarabÃ¡si-Albert graph.\")\n",
    "        ba_graph = nx.barabasi_albert_graph(num_nodes, m)\n",
    "        while not nx.is_connected(ba_graph):\n",
    "            # Add edges to connect the graph\n",
    "            non_edges = list(nx.non_edges(ba_graph))\n",
    "            edge_to_add = non_edges[0]\n",
    "            ba_graph.add_edge(*edge_to_add)\n",
    "        return ba_graph\n",
    "    m_parameter = 2\n",
    "    random_connected_ba_graph = generate_random_connected_barabasi_albert_graph(num_nodes, m_parameter)\n",
    "    main_list.append(random_connected_ba_graph)\n",
    "    #-------------------------------------------------\n",
    "    def generate_random_connected_erdos_renyi_graph(num_nodes, probability):\n",
    "        er_graph = nx.erdos_renyi_graph(num_nodes, probability)\n",
    "        while not nx.is_connected(er_graph):\n",
    "            # Add edges to connect the graph\n",
    "            non_edges = list(nx.non_edges(er_graph))\n",
    "            edge_to_add = non_edges[0]\n",
    "            er_graph.add_edge(*edge_to_add)\n",
    "        return er_graph\n",
    "    edge_probability = 0.1  # Adjust as needed\n",
    "    random_connected_er_graph = generate_random_connected_erdos_renyi_graph(num_nodes, edge_probability)\n",
    "    main_list.append(random_connected_er_graph)\n",
    "    #-------------------------------------------------\n",
    "    k = 2  # Each node is connected to k nearest neighbors\n",
    "    p = 0.3  # Probability of rewiring each edge\n",
    "    random_graph_ws = nx.watts_strogatz_graph(num_nodes, k, p)\n",
    "    main_list.append(random_graph_ws)\n",
    "    #-------------------------------------------------\n",
    "    k = 10  # Each node is connected to k nearest neighbors\n",
    "    p = 0.3  # Probability of rewiring each edge\n",
    "    random_graph_ws = nx.watts_strogatz_graph(num_nodes, k, p)\n",
    "    main_list.append(random_graph_ws)\n",
    "    #-------------------------------------------------\n",
    "\n",
    "    def generate_connected_random_geometric_graph(num_nodes, radius):\n",
    "        random_geo_graph = nx.random_geometric_graph(num_nodes, radius)\n",
    "        while not nx.is_connected(random_geo_graph):\n",
    "            # Connect the graph by adding edges\n",
    "            non_edges = list(nx.non_edges(random_geo_graph))\n",
    "            random_edge = random.choice(non_edges)\n",
    "            random_geo_graph.add_edge(*random_edge)\n",
    "        return random_geo_graph\n",
    "    radius = 0.1  # Adjust as needed\n",
    "    connected_random_geo_graph = generate_connected_random_geometric_graph(num_nodes, radius)\n",
    "    main_list.append(connected_random_geo_graph)\n",
    "    #-------------------------------------------------\n",
    "    def generate_connected_random_internet_graph(num_nodes, k, p):\n",
    "        internet_graph = nx.random_internet_as_graph(num_nodes)\n",
    "        while not nx.is_connected(internet_graph):\n",
    "            non_edges = list(nx.non_edges(internet_graph))\n",
    "            random_edge = non_edges[0]\n",
    "            internet_graph.add_edge(*random_edge)\n",
    "        undirected_internet_graph = internet_graph.to_undirected()\n",
    "        connected_random_internet_graph = nx.connected_watts_strogatz_graph(num_nodes, k, p)\n",
    "        return connected_random_internet_graph\n",
    "    k_parameter = 5\n",
    "    p_parameter = 0.5\n",
    "    connected_random_internet_graph = generate_connected_random_internet_graph(num_nodes, k_parameter, p_parameter)\n",
    "    main_list.append(connected_random_internet_graph)\n",
    "    #-------------------------------------------------\n",
    "    return main_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BigGraphs = create_Big_Graphs()\n",
    "main_list = create_main_graphs(5000)\n",
    "main_list2 = create_main_graphs(8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kernighan_lin import kernighan_lin_bisection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KernighanLinIterationAndEmbedding(G):\n",
    "    \n",
    "    total_vertices = G.number_of_nodes()\n",
    "    \n",
    "    # determine total number of iterations\n",
    "    if total_vertices < 360:\n",
    "        totalNumberOfIteration = 10\n",
    "    elif total_vertices > 500:\n",
    "        totalNumberOfIteration = 0.4 * total_vertices * np.log10(total_vertices)\n",
    "    else:\n",
    "        totalNumberOfIteration = total_vertices * np.log10(total_vertices)\n",
    "    \n",
    "    totalNumberOfIteration = int(totalNumberOfIteration)\n",
    "    \n",
    "    #for j in range(totalNumberOfIteration):\n",
    "    partition = kernighan_lin_bisection(G, max_iter=totalNumberOfIteration)\n",
    "    \n",
    "    G_partition1 = G.subgraph(partition[0])\n",
    "    G_partition2 = G.subgraph(partition[1])\n",
    "    \n",
    "    if nx.is_connected(G_partition1) and nx.is_connected(G_partition2):\n",
    "        \n",
    "        partition_1_vertices = G_partition1.number_of_nodes()\n",
    "        partition_2_vertices = G_partition2.number_of_nodes()\n",
    "        \n",
    "        min_vertex_bound = total_vertices/2 - total_vertices*0.01\n",
    "        max_vertex_bound = total_vertices/2 + total_vertices*0.01\n",
    "        \n",
    "        if ((min_vertex_bound <= partition_1_vertices <= max_vertex_bound)\n",
    "                and (min_vertex_bound <= partition_2_vertices <= max_vertex_bound)):\n",
    "            return 1\n",
    "        \n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import random as rand\n",
    "import numpy as np\n",
    "# Graph Representation & Embedding Library\n",
    "import networkx as nx \n",
    "from node2vec import Node2Vec\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbedding(G):\n",
    "    # Precompute probabilities and generate walks\n",
    "    node2vec = Node2Vec(G, dimensions=30, walk_length=6, num_walks=10, workers=6)\n",
    "\n",
    "    # Embed nodes\n",
    "    model = node2vec.fit(window=5, min_count=1, batch_words=4)\n",
    "\n",
    "    # Get embeddings for all nodes in the graph\n",
    "    all_node_embeddings = {node: model.wv[str(node)] for node in G.nodes()}\n",
    "\n",
    "    return all_node_embeddings\n",
    "    # loaded_model = Node2Vec.load(\"node2vec_model.bin\")\n",
    "    # loaded_embedding = loaded_model.wv['0']\n",
    "    # print(f\"Loaded Embedding for Node 0: {loaded_embedding}\")\n",
    "\n",
    "def dictionaryToNpArray(embedding):\n",
    "    array_from_dict = np.array(list(embedding.values()))\n",
    "    return array_from_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scriptKullanilacakFonksiyon(G):\n",
    "    # Modeli yÃ¼kleyip kullanma\n",
    "    # K-Means modelini yÃ¼kle\n",
    "    with open('logistic_regression_model.pickle', 'rb') as model_file:\n",
    "        loaded_classifier = pickle.load(model_file)\n",
    "\n",
    "    nodeEmbeddings = getEmbedding(G) \n",
    "    nodeEmbeddingsArray = dictionaryToNpArray(nodeEmbeddings)\n",
    "    graphEmbedding = np.mean(nodeEmbeddingsArray, axis=0).astype('float')\n",
    "\n",
    "    result_prediction = loaded_classifier.predict(graphEmbedding.reshape(1, -1))\n",
    "\n",
    "    # Prediction 0.5'den buyukse 1 veriyor (Yani partition edilebilir)\n",
    "    if result_prediction > 0.5:\n",
    "        return 1\n",
    "    \n",
    "    # Prediction 0.5'den kucukse 0 veriyor (Yani partition edilemedi)\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|ââââââââââ| 5000/5000 [00:00<00:00, 17986.92it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 15 features per sample; expecting 30",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-2459b1938437>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmain_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mres_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscriptKullanilacakFonksiyon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9c1ee1b79cc8>\u001b[0m in \u001b[0;36mscriptKullanilacakFonksiyon\u001b[1;34m(G)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mgraphEmbedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodeEmbeddingsArray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mresult_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraphEmbedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Prediction 0.5'den buyukse 1 veriyor (Yani partition edilebilir)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bora\\anaconda3\\envs\\test1\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \"\"\"\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bora\\anaconda3\\envs\\test1\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[1;32m--> 289\u001b[1;33m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 15 features per sample; expecting 30"
     ]
    }
   ],
   "source": [
    "label_val = []\n",
    "\n",
    "print(len(main_list))\n",
    "\n",
    "for graph in main_list:\n",
    "    label_val.append(KernighanLinIterationAndEmbedding(graph))\n",
    "    \n",
    "\n",
    "res_val = []\n",
    "\n",
    "for graph in main_list:\n",
    "    res_val.append(scriptKullanilacakFonksiyon(graph))\n",
    "    \n",
    "count = 0\n",
    "\n",
    "for i in range(len(res_val)):\n",
    "    if res_val[i] == label_val[i]:\n",
    "        count += 1\n",
    "\n",
    "print(count)\n",
    "print(len(res_val))\n",
    "print(float(count)/len(res_val))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
