{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random as rand\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from kernighan_lin import kernighan_lin_bisection\n",
    "import networkx as nx\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.mapper import GraphSAGENodeGenerator\n",
    "from stellargraph.layer import GraphSAGE\n",
    "from tensorflow.keras import layers, optimizers, losses, Model\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from stellargraph.layer import MeanPoolingAggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get from timeclock\n",
    "SEED_OF_RANDOM = 2524\n",
    "rand.seed(SEED_OF_RANDOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connected_graph(node_list):\n",
    "    # Create an empty graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes from the specific node list\n",
    "    G.add_nodes_from(node_list)\n",
    "\n",
    "    # Add edges to connect the nodes and ensure connectivity\n",
    "    while not nx.is_connected(G):\n",
    "        # Randomly select two nodes from the graph\n",
    "        node1 = rand.choice(list(G.nodes()))\n",
    "        node2 = rand.choice(list(G.nodes()))\n",
    "\n",
    "        # Add an edge between the selected nodes\n",
    "        G.add_edge(node1, node2)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate graph creation\n",
    "\n",
    "def simulate_graph_creation(min_size, max_size, min_edge_between, max_edge_between):\n",
    "        \n",
    "    # Creating Graphs\n",
    "    NUMBER_OF_NODES = rand.randint(min_size, max_size)\n",
    "        \n",
    "    nodeList_1 = np.arange(1, (NUMBER_OF_NODES+1)/2)\n",
    "    nodeList_2 = np.arange((NUMBER_OF_NODES+1)/2, NUMBER_OF_NODES+1)\n",
    "        \n",
    "    connected_graph_1 = create_connected_graph(nodeList_1)\n",
    "    connected_graph_2 = create_connected_graph(nodeList_2)\n",
    "        \n",
    "    RENAME_1 = 'G_1_' \n",
    "    RENAME_2 = 'G_2_'\n",
    "    G_union = nx.union(connected_graph_1, connected_graph_2, rename = (RENAME_1, RENAME_2))\n",
    "        \n",
    "    # Setting Edges\n",
    "    EDGES_BETWEEN_PARTITIONS = rand.randint(min_edge_between, max_edge_between)\n",
    "        \n",
    "    for i in range (EDGES_BETWEEN_PARTITIONS):\n",
    "        node1 = RENAME_1 + str(rand.randint(1, NUMBER_OF_NODES))\n",
    "        node2 = RENAME_2 + str(rand.randint(1, NUMBER_OF_NODES))\n",
    "        G_union.add_edge(node1, node2)\n",
    "        \n",
    "    return G_union, EDGES_BETWEEN_PARTITIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling\n",
    "\n",
    "def label_given_graph(graph, edges):\n",
    "    \n",
    "    partition = kernighan_lin_bisection(graph, max_iter = 200)\n",
    "    \n",
    "    G_partition1 = graph.subgraph(partition[0])\n",
    "    G_partition2 = graph.subgraph(partition[1])\n",
    "    \n",
    "    # Check Vertex Constraint\n",
    "    total_vertices = graph.number_of_nodes()\n",
    "    partition_1_vertices = G_partition1.number_of_nodes()\n",
    "    partition_2_vertices = G_partition2.number_of_nodes()\n",
    "    \n",
    "    min_vertex_bound = total_vertices/2 - total_vertices*0.01\n",
    "    max_vertex_bound = total_vertices/2 + total_vertices*0.01\n",
    "    \n",
    "    if not ((min_vertex_bound <= partition_1_vertices <= max_vertex_bound) and (min_vertex_bound <= partition_2_vertices <= max_vertex_bound)):\n",
    "        return False\n",
    "    \n",
    "    # Check Edge Constraint\n",
    "    total_edges = graph.number_of_edges()\n",
    "    partition_1_edges = G_partition1.number_of_edges()\n",
    "    partition_2_edges = G_partition2.number_of_edges()\n",
    "\n",
    "    min_cut_edge_amount = total_edges-partition_1_edges-partition_2_edges\n",
    "    \n",
    "    if edges >= min_cut_edge_amount:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get degree feature\n",
    "def get_degree_feature(graph):\n",
    "    return dict(graph.degree())\n",
    "\n",
    "# Get betweenness centrality feature\n",
    "def get_betweenness_centrality_feature(graph):\n",
    "    return nx.betweenness_centrality(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate node features\n",
    "def generate_node_features(graph, feature_functions):\n",
    "    feature_dict = {}\n",
    "    \n",
    "    # Calculate each feature using the provided functions\n",
    "    for feature_name, feature_function in feature_functions.items():\n",
    "        feature_dict[feature_name] = feature_function(graph)\n",
    "    \n",
    "    # Create a DataFrame with node features\n",
    "    node_features = pd.DataFrame(feature_dict, index=graph.nodes())\n",
    "    \n",
    "    return node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToExcel(mapping_result):\n",
    "    desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "    file_path = os.path.join(desktop_path, \"graph_mapping.xlsx\")\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        with pd.ExcelWriter(file_path, engine=\"openpyxl\", mode=\"a\") as writer:\n",
    "            df = pd.DataFrame.from_dict(mapping_result, orient=\"index\")\n",
    "            startcol = len(writer.sheets[\"Sheet1\"].columns) if \"Sheet1\" in writer.sheets else 0\n",
    "            df.to_excel(writer, sheet_name=\"Sheet1\", startcol=startcol, index=True)\n",
    "    else:\n",
    "        with pd.ExcelWriter(file_path, engine=\"openpyxl\") as writer:\n",
    "            df = pd.DataFrame.from_dict(mapping_result, orient=\"index\")\n",
    "            df.to_excel(writer, sheet_name=\"Sheet1\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "83\n",
      "5        0\n",
      "girdi1\n",
      "225\n",
      "182\n",
      "10        0\n",
      "7        1\n",
      "9        2\n",
      "8        3\n",
      "7        8\n",
      "8        9\n",
      "girdi2\n",
      "198\n",
      "173\n",
      "8        1\n",
      "8        2\n",
      "7        3\n",
      "8        4\n",
      "8        8\n",
      "8        9\n",
      "girdi2\n",
      "97\n",
      "85\n",
      "6        6\n",
      "girdi1\n"
     ]
    }
   ],
   "source": [
    "import differentGraphs as dg\n",
    "\n",
    "TOTAL_NUMBER_OF_GRAPH_FOR_EACH = 4\n",
    "NODES_LOW_LIMIT = 60\n",
    "NODES_HIGH_LIMIT = 200\n",
    "\n",
    "excel_file_path = 'output.xlsx'\n",
    "\n",
    "def writeToExcel(embeddings):\n",
    "    df = pd.DataFrame(embeddings, columns=[f'Column{i}' for i in range(1, len(embeddings[0])+1)])\n",
    "    if os.path.exists(excel_file_path):\n",
    "        # İkinci DataFrame'i dosyaya ekleyerek yaz\n",
    "        with pd.ExcelWriter(excel_file_path, engine='openpyxl', mode='a') as writer:\n",
    "            df.to_excel(writer, index=False, header=False)\n",
    "    else:\n",
    "        df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "\n",
    "def get_embedding_SAGE(G):\n",
    "    \n",
    "    feature_functions = {\n",
    "        'degree': get_degree_feature,\n",
    "        'betweenness_centrality': get_betweenness_centrality_feature,\n",
    "        # Add more features as needed\n",
    "    }\n",
    "    \n",
    "    # Assuming you have a function to generate node features, modify as needed\n",
    "    node_features = generate_node_features(G, feature_functions)\n",
    "    \n",
    "    # Convert NetworkX graph to StellarGraph with node features\n",
    "    G_stellar = StellarGraph.from_networkx(G, node_features=node_features)\n",
    "\n",
    "    # generator\n",
    "    # batch_size -> number of nodes per batch\n",
    "    # num_samples -> number of neighbours per layer\n",
    "    generator = GraphSAGENodeGenerator(G_stellar, batch_size=50, num_samples=[10, 10])\n",
    "    \n",
    "    model = GraphSAGE(layer_sizes=[50, 50], generator=generator, aggregator=MeanPoolingAggregator, bias=True, dropout=0.5)\n",
    "    \n",
    "    # get input and output tensors\n",
    "    x_inp, x_out = model.in_out_tensors()\n",
    "\n",
    "    output_size = 30\n",
    "    \n",
    "    # pass the output tensor through the classification layer\n",
    "    prediction = layers.Dense(units=output_size, activation=\"linear\")(x_out)\n",
    "\n",
    "    # Combine the GraphSAGE model with the prediction layer\n",
    "    model = Model(inputs=x_inp, outputs=prediction)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizers.Adam(lr=1e-3), loss=losses.binary_crossentropy, metrics=[\"acc\"])\n",
    "\n",
    "    #model.summary()\n",
    "    \n",
    "    # Obtain the graph embedding for all nodes\n",
    "    node_ids = G_stellar.nodes()\n",
    "    node_gen = generator.flow(node_ids) # If we have test train vs sets this 3 lines will be copied\n",
    "    node_embeddings = model.predict(node_gen)\n",
    "        \n",
    "    return node_embeddings[1]\n",
    "\n",
    "\n",
    "def dictionaryToNpArray(embedding):\n",
    "    array_from_dict = np.array(list(embedding.values()))\n",
    "    return array_from_dict\n",
    "\n",
    "def KernighanLinIterationAndSAGEembedding(totalNumberOfIteration, G):\n",
    "    didItBecomeConnected = False\n",
    "    graphEmbedding = []\n",
    "    for j in range(totalNumberOfIteration):\n",
    "        partition = kernighan_lin_bisection(G,max_iter = 1000)\n",
    "        G_partition1 = G.subgraph(partition[0])\n",
    "        G_partition2 = G.subgraph(partition[1])\n",
    "        if nx.is_connected(G_partition1) and nx.is_connected(G_partition2):\n",
    "            didItBecomeConnected = True\n",
    "            total_edges = G.number_of_edges()\n",
    "            partition_1_edges = G_partition1.number_of_edges()\n",
    "            partition_2_edges = G_partition2.number_of_edges()\n",
    "            edgeBetweenSubGraphs = total_edges-partition_1_edges-partition_2_edges\n",
    "            # Buradaki maksimum edge belirlenecek\n",
    "            # TODO matemetigi getirilecek\n",
    "            print(str(edgeBetweenSubGraphs) + \"        \" + str(j))\n",
    "            if edgeBetweenSubGraphs < 7: \n",
    "                print('girdi1')   \n",
    "                graphEmbeddingTemp = get_embedding_SAGE(G) \n",
    "                graphEmbedding = np.append(graphEmbeddingTemp, 1)\n",
    "                break\n",
    "            \n",
    "        # Sona geldiysek ve hala Yes label alamadıysa No label ver\n",
    "        # Eger hicbir zaman connected bir sekilde bolunemediyse hicbir sey yapma\n",
    "        if j == totalNumberOfIteration-1 and didItBecomeConnected:\n",
    "            print('girdi2')\n",
    "            graphEmbeddingTemp = get_embedding_SAGE(G) \n",
    "            graphEmbedding = np.append(graphEmbeddingTemp, 0)\n",
    "            break\n",
    "    return didItBecomeConnected,graphEmbedding    \n",
    "\n",
    "def dataGenerateAndSave(numberOfNodesLowest, numberOfNodesHighest):\n",
    "    df=[]\n",
    "    graphEmbedding = []\n",
    "    seed = rand.randint(1,1000000)\n",
    "    numberOfNodes = rand.randint(numberOfNodesLowest,numberOfNodesHighest)\n",
    "\n",
    "    i = TOTAL_NUMBER_OF_GRAPH_FOR_EACH\n",
    "    # Number 6 Planar_graph\n",
    "    while i>0:\n",
    "        numberOfNodes = rand.randint(numberOfNodesLowest,numberOfNodesHighest)\n",
    "        numberOfEdges = rand.randint(int(numberOfNodes*1.15),int(numberOfNodes*1.3))\n",
    "        G = dg.generate_planar_graph(nodes=numberOfNodes,edges=numberOfEdges)\n",
    "        print(nx.number_of_edges(G))\n",
    "        print(nx.number_of_nodes(G))\n",
    "        while not nx.is_connected(G):\n",
    "            numberOfNodes = rand.randint(numberOfNodesLowest,numberOfNodesHighest)\n",
    "            numberOfEdges = rand.randint(int(numberOfNodes*1.15),int(numberOfNodes*1.3))\n",
    "            G = dg.generate_planar_graph(nodes=numberOfNodes,edges=numberOfEdges)\n",
    "\n",
    "        totalNumberOfIteration = 10\n",
    "        didItBecomeConnected, graphEmbedding = KernighanLinIterationAndSAGEembedding(totalNumberOfIteration,G)\n",
    "        if didItBecomeConnected and len(graphEmbedding)>0:\n",
    "            i = i-1\n",
    "            if len(df) == 0:\n",
    "                df = graphEmbedding\n",
    "            else : \n",
    "                df = np.vstack((df, graphEmbedding))\n",
    "\n",
    "    writeToExcel(df)\n",
    "\n",
    "\n",
    "\n",
    "def make_graph_connected(G):\n",
    "    \n",
    "    while not nx.is_connected(G):\n",
    "        # Randomly select two nodes from the graph\n",
    "        node1 = rand.choice(list(G.nodes()))\n",
    "        node2 = rand.choice(list(G.nodes()))\n",
    "\n",
    "        # Add an edge between the selected nodes\n",
    "        G.add_edge(node1, node2)\n",
    "        \n",
    "    return G\n",
    "\n",
    "# Gets a graph and makes is connected\n",
    "def is_graph_appropriate(graph):\n",
    "    # Check if the graph is None\n",
    "    if graph is None:\n",
    "        return False\n",
    "\n",
    "    # Check if the graph is empty\n",
    "    if len(graph.nodes()) == 0:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "dataGenerateAndSave(NODES_LOW_LIMIT,NODES_HIGH_LIMIT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-d0aaeab35214>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mmapping_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mwriteToExcel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapping_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-42-01193331e6b0>\u001b[0m in \u001b[0;36mwriteToExcel\u001b[1;34m(embeddings)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwriteToExcel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'Column{i}'\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexcel_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# İkinci DataFrame'i dosyaya ekleyerek yaz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# testing \n",
    "\n",
    "TEST_AMOUNT = 1\n",
    "\n",
    "for i in range(TEST_AMOUNT):\n",
    "    # Simulate graph creation\n",
    "    G, edges = simulate_graph_creation(100, 500, 2, 5)\n",
    "\n",
    "    # Label the graph\n",
    "    label_val = label_given_graph(G, edges)\n",
    "    \n",
    "    \n",
    "    feature_functions = {\n",
    "        'degree': get_degree_feature,\n",
    "        'betweenness_centrality': get_betweenness_centrality_feature,\n",
    "        # Add more features as needed\n",
    "    }\n",
    "    \n",
    "    # Assuming you have a function to generate node features, modify as needed\n",
    "    node_features = generate_node_features(G, feature_functions)\n",
    "    \n",
    "    # Convert NetworkX graph to StellarGraph with node features\n",
    "    G_stellar = StellarGraph.from_networkx(G, node_features=node_features)\n",
    "\n",
    "    # generator\n",
    "    # batch_size -> number of nodes per batch\n",
    "    # num_samples -> number of neighbours per layer\n",
    "    generator = GraphSAGENodeGenerator(G_stellar, batch_size=50, num_samples=[10, 10])\n",
    "    \n",
    "    model = GraphSAGE(layer_sizes=[50, 50], generator=generator, aggregator=MeanPoolingAggregator, bias=True, dropout=0.5)\n",
    "    \n",
    "    # get input and output tensors\n",
    "    x_inp, x_out = model.in_out_tensors()\n",
    "\n",
    "    output_size = 10\n",
    "    \n",
    "    # pass the output tensor through the classification layer\n",
    "    prediction = layers.Dense(units=output_size, activation=\"linear\")(x_out)\n",
    "\n",
    "    # Combine the GraphSAGE model with the prediction layer\n",
    "    model = Model(inputs=x_inp, outputs=prediction)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizers.Adam(lr=1e-3), loss=losses.binary_crossentropy, metrics=[\"acc\"])\n",
    "\n",
    "    #model.summary()\n",
    "    \n",
    "    # Obtain the graph embedding for all nodes\n",
    "    node_ids = G_stellar.nodes()\n",
    "    node_gen = generator.flow(node_ids) # If we have test train vs sets this 3 lines will be copied\n",
    "    node_embeddings = model.predict(node_gen)\n",
    "    \n",
    "    #print(node_embeddings.shape)\n",
    "\n",
    "    # Map the representation with label_val (assuming label_val is boolean)\n",
    "    mapping_result = dict(zip(node_ids, node_embeddings[1].flatten()))\n",
    "    \n",
    "    # Add the label information to mapping_result\n",
    "    mapping_result['label'] = label_val\n",
    "    \n",
    "    writeToExcel(mapping_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
