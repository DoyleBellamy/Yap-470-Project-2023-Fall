{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random as rand\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from kernighan_lin import kernighan_lin_bisection\n",
    "import networkx as nx\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.mapper import GraphSAGENodeGenerator\n",
    "from stellargraph.layer import GraphSAGE\n",
    "from tensorflow.keras import layers, optimizers, losses, Model\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from stellargraph.layer import MeanPoolingAggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get from timeclock\n",
    "SEED_OF_RANDOM = 2524\n",
    "rand.seed(SEED_OF_RANDOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connected_graph(node_list):\n",
    "    # Create an empty graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes from the specific node list\n",
    "    G.add_nodes_from(node_list)\n",
    "\n",
    "    # Add edges to connect the nodes and ensure connectivity\n",
    "    while not nx.is_connected(G):\n",
    "        # Randomly select two nodes from the graph\n",
    "        node1 = rand.choice(list(G.nodes()))\n",
    "        node2 = rand.choice(list(G.nodes()))\n",
    "\n",
    "        # Add an edge between the selected nodes\n",
    "        G.add_edge(node1, node2)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate graph creation\n",
    "\n",
    "def simulate_graph_creation(min_size, max_size, min_edge_between, max_edge_between):\n",
    "        \n",
    "    # Creating Graphs\n",
    "    NUMBER_OF_NODES = rand.randint(min_size, max_size)\n",
    "        \n",
    "    nodeList_1 = np.arange(1, (NUMBER_OF_NODES+1)/2)\n",
    "    nodeList_2 = np.arange((NUMBER_OF_NODES+1)/2, NUMBER_OF_NODES+1)\n",
    "        \n",
    "    connected_graph_1 = create_connected_graph(nodeList_1)\n",
    "    connected_graph_2 = create_connected_graph(nodeList_2)\n",
    "        \n",
    "    RENAME_1 = 'G_1_' \n",
    "    RENAME_2 = 'G_2_'\n",
    "    G_union = nx.union(connected_graph_1, connected_graph_2, rename = (RENAME_1, RENAME_2))\n",
    "        \n",
    "    # Setting Edges\n",
    "    EDGES_BETWEEN_PARTITIONS = rand.randint(min_edge_between, max_edge_between)\n",
    "        \n",
    "    for i in range (EDGES_BETWEEN_PARTITIONS):\n",
    "        node1 = RENAME_1 + str(rand.randint(1, NUMBER_OF_NODES))\n",
    "        node2 = RENAME_2 + str(rand.randint(1, NUMBER_OF_NODES))\n",
    "        G_union.add_edge(node1, node2)\n",
    "        \n",
    "    return G_union, EDGES_BETWEEN_PARTITIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling\n",
    "\n",
    "def label_given_graph(graph, edges):\n",
    "    \n",
    "    partition = kernighan_lin_bisection(graph, max_iter = 200)\n",
    "    \n",
    "    G_partition1 = graph.subgraph(partition[0])\n",
    "    G_partition2 = graph.subgraph(partition[1])\n",
    "    \n",
    "    # Check Vertex Constraint\n",
    "    total_vertices = graph.number_of_nodes()\n",
    "    partition_1_vertices = G_partition1.number_of_nodes()\n",
    "    partition_2_vertices = G_partition2.number_of_nodes()\n",
    "    \n",
    "    min_vertex_bound = total_vertices/2 - total_vertices*0.01\n",
    "    max_vertex_bound = total_vertices/2 + total_vertices*0.01\n",
    "    \n",
    "    if not ((min_vertex_bound <= partition_1_vertices <= max_vertex_bound) and (min_vertex_bound <= partition_2_vertices <= max_vertex_bound)):\n",
    "        return False\n",
    "    \n",
    "    # Check Edge Constraint\n",
    "    total_edges = graph.number_of_edges()\n",
    "    partition_1_edges = G_partition1.number_of_edges()\n",
    "    partition_2_edges = G_partition2.number_of_edges()\n",
    "\n",
    "    min_cut_edge_amount = total_edges-partition_1_edges-partition_2_edges\n",
    "    \n",
    "    if edges >= min_cut_edge_amount:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get degree feature\n",
    "def get_degree_feature(graph):\n",
    "    return dict(graph.degree())\n",
    "\n",
    "# Get betweenness centrality feature\n",
    "def get_betweenness_centrality_feature(graph):\n",
    "    return nx.betweenness_centrality(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate node features\n",
    "def generate_node_features(graph, feature_functions):\n",
    "    feature_dict = {}\n",
    "    \n",
    "    # Calculate each feature using the provided functions\n",
    "    for feature_name, feature_function in feature_functions.items():\n",
    "        feature_dict[feature_name] = feature_function(graph)\n",
    "    \n",
    "    # Create a DataFrame with node features\n",
    "    node_features = pd.DataFrame(feature_dict, index=graph.nodes())\n",
    "    \n",
    "    return node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToExcel(mapping_result):\n",
    "    desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "    file_path = os.path.join(desktop_path, \"graph_mapping.xlsx\")\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        with pd.ExcelWriter(file_path, engine=\"openpyxl\", mode=\"a\") as writer:\n",
    "            df = pd.DataFrame.from_dict(mapping_result, orient=\"index\")\n",
    "            startcol = len(writer.sheets[\"Sheet1\"].columns) if \"Sheet1\" in writer.sheets else 0\n",
    "            df.to_excel(writer, sheet_name=\"Sheet1\", startcol=startcol, index=True)\n",
    "    else:\n",
    "        with pd.ExcelWriter(file_path, engine=\"openpyxl\") as writer:\n",
    "            df = pd.DataFrame.from_dict(mapping_result, orient=\"index\")\n",
    "            df.to_excel(writer, sheet_name=\"Sheet1\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(459, 10)\n"
     ]
    }
   ],
   "source": [
    "# testing \n",
    "\n",
    "TEST_AMOUNT = 1\n",
    "\n",
    "for i in range(TEST_AMOUNT):\n",
    "    # Simulate graph creation\n",
    "    G, edges = simulate_graph_creation(100, 500, 2, 5)\n",
    "\n",
    "    # Label the graph\n",
    "    label_val = label_given_graph(G, edges)\n",
    "    \n",
    "    \n",
    "    feature_functions = {\n",
    "        'degree': get_degree_feature,\n",
    "        'betweenness_centrality': get_betweenness_centrality_feature,\n",
    "        # Add more features as needed\n",
    "    }\n",
    "    \n",
    "    # Assuming you have a function to generate node features, modify as needed\n",
    "    node_features = generate_node_features(G, feature_functions)\n",
    "    \n",
    "    # Convert NetworkX graph to StellarGraph with node features\n",
    "    G_stellar = StellarGraph.from_networkx(G, node_features=node_features)\n",
    "\n",
    "    # generator\n",
    "    # batch_size -> number of nodes per batch\n",
    "    # num_samples -> number of neighbours per layer\n",
    "    generator = GraphSAGENodeGenerator(G_stellar, batch_size=50, num_samples=[10, 10])\n",
    "    \n",
    "    model = GraphSAGE(layer_sizes=[50, 50], generator=generator, aggregator=MeanPoolingAggregator, bias=True, dropout=0.5)\n",
    "    \n",
    "    # get input and output tensors\n",
    "    x_inp, x_out = model.in_out_tensors()\n",
    "\n",
    "    output_size = 10\n",
    "    \n",
    "    # pass the output tensor through the classification layer\n",
    "    prediction = layers.Dense(units=output_size, activation=\"linear\")(x_out)\n",
    "\n",
    "    # Combine the GraphSAGE model with the prediction layer\n",
    "    model = Model(inputs=x_inp, outputs=prediction)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizers.Adam(lr=1e-3), loss=losses.binary_crossentropy, metrics=[\"acc\"])\n",
    "\n",
    "    #model.summary()\n",
    "    \n",
    "    # Obtain the graph embedding for all nodes\n",
    "    node_ids = G_stellar.nodes()\n",
    "    node_gen = generator.flow(node_ids) # If we have test train vs sets this 3 lines will be copied\n",
    "    node_embeddings = model.predict(node_gen)\n",
    "    \n",
    "    print(node_embeddings.shape)\n",
    "\n",
    "    # Map the representation with label_val (assuming label_val is boolean)\n",
    "    mapping_result = dict(zip(node_ids, node_embeddings[1].flatten()))\n",
    "    \n",
    "    # Add the label information to mapping_result\n",
    "    mapping_result['label'] = label_val\n",
    "    \n",
    "    writeToExcel(mapping_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
